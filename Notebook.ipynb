{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82695,"databundleVersionId":9738540,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Introduction \n\nThis code focuses on building and improving a multi-class classification model using techniques like resampling (SMOTE and ADASYN) to handle class imbalance, feature engineering (dimensionality reduction and interaction terms) to optimize the feature space, and hyperparameter tuning (grid search for XGBoost) to enhance model performance. It evaluates the model using accuracy, precision, recall, and F1-score to identify areas of improvement, exploring advanced methods like SMOTEENN and incremental PCA to balance the dataset and reduce computational overhead. The goal is to develop a robust pipeline for training and testing a model that effectively handles imbalanced and high-dimensional data.","metadata":{}},{"cell_type":"markdown","source":"# 1. Setup and Imports","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n# Download necessary NLTK data\nnltk.download('punkt')\nnltk.download('stopwords')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:10.289500Z","iopub.execute_input":"2024-12-10T07:43:10.290328Z","iopub.status.idle":"2024-12-10T07:43:15.034108Z","shell.execute_reply.started":"2024-12-10T07:43:10.290280Z","shell.execute_reply":"2024-12-10T07:43:15.032616Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"# 2. Data Loading","metadata":{}},{"cell_type":"code","source":"# Load dataset\ntrain_data = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\")  \ntest_data = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\") \nmisconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")  \n\n# Display the first few rows of train data\ntrain_data.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:15.036636Z","iopub.execute_input":"2024-12-10T07:43:15.037251Z","iopub.status.idle":"2024-12-10T07:43:15.132075Z","shell.execute_reply.started":"2024-12-10T07:43:15.037158Z","shell.execute_reply":"2024-12-10T07:43:15.130934Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   QuestionId  ConstructId                                      ConstructName  \\\n0           0          856  Use the order of operations to carry out calcu...   \n1           1         1612  Simplify an algebraic fraction by factorising ...   \n2           2         2774            Calculate the range from a list of data   \n3           3         2377  Recall and use the intersecting diagonals prop...   \n4           4         3387  Substitute positive integer values into formul...   \n\n   SubjectId                                        SubjectName CorrectAnswer  \\\n0         33                                             BIDMAS             A   \n1       1077                    Simplifying Algebraic Fractions             D   \n2        339  Range and Interquartile Range from a List of Data             B   \n3         88                       Properties of Quadrilaterals             C   \n4         67                          Substitution into Formula             A   \n\n                                        QuestionText            AnswerAText  \\\n0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n3  The angles highlighted on this rectangle with ...                  acute   \n4  The equation \\( f=3 r^{2}+3 \\) is used to find...               \\( 30 \\)   \n\n              AnswerBText            AnswerCText             AnswerDText  \\\n0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n3                  obtuse       \\( 90^{\\circ} \\)  Not enough information   \n4                \\( 27 \\)               \\( 51 \\)                \\( 24 \\)   \n\n   MisconceptionAId  MisconceptionBId  MisconceptionCId  MisconceptionDId  \n0               NaN               NaN               NaN            1672.0  \n1            2142.0             143.0            2142.0               NaN  \n2            1287.0               NaN            1287.0            1073.0  \n3            1180.0            1180.0               NaN            1180.0  \n4               NaN               NaN               NaN            1818.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QuestionId</th>\n      <th>ConstructId</th>\n      <th>ConstructName</th>\n      <th>SubjectId</th>\n      <th>SubjectName</th>\n      <th>CorrectAnswer</th>\n      <th>QuestionText</th>\n      <th>AnswerAText</th>\n      <th>AnswerBText</th>\n      <th>AnswerCText</th>\n      <th>AnswerDText</th>\n      <th>MisconceptionAId</th>\n      <th>MisconceptionBId</th>\n      <th>MisconceptionCId</th>\n      <th>MisconceptionDId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>856</td>\n      <td>Use the order of operations to carry out calcu...</td>\n      <td>33</td>\n      <td>BIDMAS</td>\n      <td>A</td>\n      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n      <td>\\( 3 \\times(2+4)-5 \\)</td>\n      <td>\\( 3 \\times 2+(4-5) \\)</td>\n      <td>\\( 3 \\times(2+4-5) \\)</td>\n      <td>Does not need brackets</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1672.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1612</td>\n      <td>Simplify an algebraic fraction by factorising ...</td>\n      <td>1077</td>\n      <td>Simplifying Algebraic Fractions</td>\n      <td>D</td>\n      <td>Simplify the following, if possible: \\( \\frac{...</td>\n      <td>\\( m+1 \\)</td>\n      <td>\\( m+2 \\)</td>\n      <td>\\( m-1 \\)</td>\n      <td>Does not simplify</td>\n      <td>2142.0</td>\n      <td>143.0</td>\n      <td>2142.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2774</td>\n      <td>Calculate the range from a list of data</td>\n      <td>339</td>\n      <td>Range and Interquartile Range from a List of Data</td>\n      <td>B</td>\n      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n      <td>Only\\nTom</td>\n      <td>Only\\nKatie</td>\n      <td>Both Tom and Katie</td>\n      <td>Neither is correct</td>\n      <td>1287.0</td>\n      <td>NaN</td>\n      <td>1287.0</td>\n      <td>1073.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2377</td>\n      <td>Recall and use the intersecting diagonals prop...</td>\n      <td>88</td>\n      <td>Properties of Quadrilaterals</td>\n      <td>C</td>\n      <td>The angles highlighted on this rectangle with ...</td>\n      <td>acute</td>\n      <td>obtuse</td>\n      <td>\\( 90^{\\circ} \\)</td>\n      <td>Not enough information</td>\n      <td>1180.0</td>\n      <td>1180.0</td>\n      <td>NaN</td>\n      <td>1180.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>3387</td>\n      <td>Substitute positive integer values into formul...</td>\n      <td>67</td>\n      <td>Substitution into Formula</td>\n      <td>A</td>\n      <td>The equation \\( f=3 r^{2}+3 \\) is used to find...</td>\n      <td>\\( 30 \\)</td>\n      <td>\\( 27 \\)</td>\n      <td>\\( 51 \\)</td>\n      <td>\\( 24 \\)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1818.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# 3. Data Exploration","metadata":{}},{"cell_type":"code","source":"# Summary of the dataset\nprint(\"Train Data Info:\")\nprint(train_data.info())\n\nprint(\"\\nTest Data Info:\")\nprint(test_data.info())\n\nprint(\"\\nMisconception Mapping Info:\")\nprint(misconception_mapping.info())\n\n# Check for missing values\nprint(\"\\nMissing Values in Train Data:\")\nprint(train_data.isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:15.133515Z","iopub.execute_input":"2024-12-10T07:43:15.133842Z","iopub.status.idle":"2024-12-10T07:43:15.183325Z","shell.execute_reply.started":"2024-12-10T07:43:15.133810Z","shell.execute_reply":"2024-12-10T07:43:15.182112Z"}},"outputs":[{"name":"stdout","text":"Train Data Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1869 entries, 0 to 1868\nData columns (total 15 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   QuestionId        1869 non-null   int64  \n 1   ConstructId       1869 non-null   int64  \n 2   ConstructName     1869 non-null   object \n 3   SubjectId         1869 non-null   int64  \n 4   SubjectName       1869 non-null   object \n 5   CorrectAnswer     1869 non-null   object \n 6   QuestionText      1869 non-null   object \n 7   AnswerAText       1869 non-null   object \n 8   AnswerBText       1869 non-null   object \n 9   AnswerCText       1869 non-null   object \n 10  AnswerDText       1869 non-null   object \n 11  MisconceptionAId  1135 non-null   float64\n 12  MisconceptionBId  1118 non-null   float64\n 13  MisconceptionCId  1080 non-null   float64\n 14  MisconceptionDId  1037 non-null   float64\ndtypes: float64(4), int64(3), object(8)\nmemory usage: 219.1+ KB\nNone\n\nTest Data Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3 entries, 0 to 2\nData columns (total 11 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   QuestionId     3 non-null      int64 \n 1   ConstructId    3 non-null      int64 \n 2   ConstructName  3 non-null      object\n 3   SubjectId      3 non-null      int64 \n 4   SubjectName    3 non-null      object\n 5   CorrectAnswer  3 non-null      object\n 6   QuestionText   3 non-null      object\n 7   AnswerAText    3 non-null      object\n 8   AnswerBText    3 non-null      object\n 9   AnswerCText    3 non-null      object\n 10  AnswerDText    3 non-null      object\ndtypes: int64(3), object(8)\nmemory usage: 392.0+ bytes\nNone\n\nMisconception Mapping Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2587 entries, 0 to 2586\nData columns (total 2 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   MisconceptionId    2587 non-null   int64 \n 1   MisconceptionName  2587 non-null   object\ndtypes: int64(1), object(1)\nmemory usage: 40.5+ KB\nNone\n\nMissing Values in Train Data:\nQuestionId            0\nConstructId           0\nConstructName         0\nSubjectId             0\nSubjectName           0\nCorrectAnswer         0\nQuestionText          0\nAnswerAText           0\nAnswerBText           0\nAnswerCText           0\nAnswerDText           0\nMisconceptionAId    734\nMisconceptionBId    751\nMisconceptionCId    789\nMisconceptionDId    832\ndtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 4. Preprocessing","metadata":{}},{"cell_type":"code","source":"# Initialize text preprocessing tools\nstop_words = set(stopwords.words('english'))\nstemmer = PorterStemmer()\n\n# Function to preprocess text\ndef preprocess_text(text):\n    tokens = word_tokenize(text.lower())\n    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n    tokens = [stemmer.stem(word) for word in tokens]\n    return \" \".join(tokens)\n\n# Apply preprocessing to relevant columns\ntrain_data['QuestionText'] = train_data['QuestionText'].apply(preprocess_text)\ntrain_data['AnswerAText'] = train_data['AnswerAText'].apply(preprocess_text)\ntrain_data['AnswerBText'] = train_data['AnswerBText'].apply(preprocess_text)\ntrain_data['AnswerCText'] = train_data['AnswerCText'].apply(preprocess_text)\ntrain_data['AnswerDText'] = train_data['AnswerDText'].apply(preprocess_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:15.185701Z","iopub.execute_input":"2024-12-10T07:43:15.186079Z","iopub.status.idle":"2024-12-10T07:43:17.297780Z","shell.execute_reply.started":"2024-12-10T07:43:15.186044Z","shell.execute_reply":"2024-12-10T07:43:17.296654Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# 5. Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Combine question and answer text for vectorization\ntrain_data['CombinedText'] = (\n    train_data['QuestionText'] + \" \" +\n    train_data['AnswerAText'] + \" \" +\n    train_data['AnswerBText'] + \" \" +\n    train_data['AnswerCText'] + \" \" +\n    train_data['AnswerDText']\n)\n\n# TF-IDF vectorization\ntfidf = TfidfVectorizer(max_features=10000)\nX = tfidf.fit_transform(train_data['CombinedText'])\ny = train_data[['MisconceptionAId', 'MisconceptionBId', 'MisconceptionCId']]\n\n# Flatten labels for multi-label classification\nmlb = MultiLabelBinarizer()\ny_binary = mlb.fit_transform(y.values.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.298789Z","iopub.execute_input":"2024-12-10T07:43:17.299124Z","iopub.status.idle":"2024-12-10T07:43:17.398702Z","shell.execute_reply.started":"2024-12-10T07:43:17.299091Z","shell.execute_reply":"2024-12-10T07:43:17.397306Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# 6. Model Training","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Assuming X_train and y_binary are properly defined\n# Replace these with your actual data\n# Example setup:\nX_train = np.random.rand(100, 5)  # 100 samples with 5 features each (example data)\ny_binary = np.random.randint(2, size=(100, 3))  # 100 samples with 3 binary labels (example data)\n\n# Calculate label frequencies\nlabel_counts = y_binary.sum(axis=0)  # Sum along the rows to count occurrences of each label\n\n# Find problematic labels\nalways_present_labels = np.where(label_counts == X_train.shape[0])[0]  # Labels present in all samples\nmissing_labels = np.where(label_counts == 0)[0]  # Labels missing in all samples\n\n# Output results\nprint(f\"Always present labels: {always_present_labels}\")\nprint(f\"Missing labels: {missing_labels}\")\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.400829Z","iopub.execute_input":"2024-12-10T07:43:17.401368Z","iopub.status.idle":"2024-12-10T07:43:17.412905Z","shell.execute_reply.started":"2024-12-10T07:43:17.401312Z","shell.execute_reply":"2024-12-10T07:43:17.411508Z"}},"outputs":[{"name":"stdout","text":"Always present labels: []\nMissing labels: []\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Check for labels present in all samples\nalways_present_labels = np.where((y_binary.sum(axis=0)) == X_train.shape[0])[0]\n\n# Output details of these labels\nprint(f\"Always present labels: {always_present_labels}\")\nprint(\"Classes of always present labels:\")\nprint([mlb.classes_[i] for i in always_present_labels])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.415133Z","iopub.execute_input":"2024-12-10T07:43:17.415689Z","iopub.status.idle":"2024-12-10T07:43:17.435760Z","shell.execute_reply.started":"2024-12-10T07:43:17.415649Z","shell.execute_reply":"2024-12-10T07:43:17.434195Z"}},"outputs":[{"name":"stdout","text":"Always present labels: []\nClasses of always present labels:\n[]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\n\n# Example: One-hot encoded y_train\ny_train = np.array([\n    [1, 0, 0],\n    [0, 1, 0],\n    [0, 0, 1],\n    [1, 0, 0]\n])  # Shape (4, 3)\n\n# Convert one-hot encoded y_train to a single-column format\nif len(y_train.shape) > 1 and y_train.shape[1] > 1:\n    y_train = np.argmax(y_train, axis=1)\n\nprint(\"Converted y_train:\", y_train)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.437427Z","iopub.execute_input":"2024-12-10T07:43:17.438040Z","iopub.status.idle":"2024-12-10T07:43:17.457004Z","shell.execute_reply.started":"2024-12-10T07:43:17.437992Z","shell.execute_reply":"2024-12-10T07:43:17.455576Z"}},"outputs":[{"name":"stdout","text":"Converted y_train: [0 1 2 0]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.458732Z","iopub.execute_input":"2024-12-10T07:43:17.459161Z","iopub.status.idle":"2024-12-10T07:43:17.471993Z","shell.execute_reply.started":"2024-12-10T07:43:17.459123Z","shell.execute_reply":"2024-12-10T07:43:17.470763Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (100, 5)\ny_train shape: (4,)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming X and y are defined\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.476465Z","iopub.execute_input":"2024-12-10T07:43:17.476883Z","iopub.status.idle":"2024-12-10T07:43:17.496927Z","shell.execute_reply.started":"2024-12-10T07:43:17.476846Z","shell.execute_reply":"2024-12-10T07:43:17.495308Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from collections import Counter\nprint(\"Class distribution in y_train:\", Counter(y_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.498692Z","iopub.execute_input":"2024-12-10T07:43:17.499133Z","iopub.status.idle":"2024-12-10T07:43:17.510547Z","shell.execute_reply.started":"2024-12-10T07:43:17.499097Z","shell.execute_reply":"2024-12-10T07:43:17.508986Z"}},"outputs":[{"name":"stdout","text":"Class distribution in y_train: Counter({'MisconceptionAId': 1, 'MisconceptionBId': 1, 'MisconceptionCId': 1})\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.512494Z","iopub.execute_input":"2024-12-10T07:43:17.513137Z","iopub.status.idle":"2024-12-10T07:43:17.526322Z","shell.execute_reply.started":"2024-12-10T07:43:17.513091Z","shell.execute_reply":"2024-12-10T07:43:17.524950Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (1495, 1900)\ny_train shape: (1495, 3)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\n\n# Flatten y_train if it contains one-hot encoding\nif len(y_train.shape) > 1 and y_train.shape[1] > 1:\n    y_train = np.argmax(y_train, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.529004Z","iopub.execute_input":"2024-12-10T07:43:17.529452Z","iopub.status.idle":"2024-12-10T07:43:17.540146Z","shell.execute_reply.started":"2024-12-10T07:43:17.529413Z","shell.execute_reply":"2024-12-10T07:43:17.538867Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(random_state=42)\nX_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.542065Z","iopub.execute_input":"2024-12-10T07:43:17.542446Z","iopub.status.idle":"2024-12-10T07:43:17.962957Z","shell.execute_reply.started":"2024-12-10T07:43:17.542409Z","shell.execute_reply":"2024-12-10T07:43:17.961630Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Check data types\nprint(\"X_train dtype:\", X_train.dtype)\nprint(\"y_train dtype:\", y_train.dtype)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.964147Z","iopub.execute_input":"2024-12-10T07:43:17.964748Z","iopub.status.idle":"2024-12-10T07:43:17.972267Z","shell.execute_reply.started":"2024-12-10T07:43:17.964708Z","shell.execute_reply":"2024-12-10T07:43:17.970704Z"}},"outputs":[{"name":"stdout","text":"X_train dtype: float64\ny_train dtype: int64\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Example: Convert non-numeric data to numeric using LabelEncoder\nif X_train.dtype == 'object':\n    encoder = LabelEncoder()\n    X_train = X_train.apply(encoder.fit_transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.974197Z","iopub.execute_input":"2024-12-10T07:43:17.974721Z","iopub.status.idle":"2024-12-10T07:43:17.987960Z","shell.execute_reply.started":"2024-12-10T07:43:17.974672Z","shell.execute_reply":"2024-12-10T07:43:17.986613Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Convert y_train to numeric if it's an object or string\nif y_train.dtype == 'object':\n    unique_labels = np.unique(y_train)\n    label_map = {label: idx for idx, label in enumerate(unique_labels)}\n    y_train = y_train.map(label_map)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:17.989524Z","iopub.execute_input":"2024-12-10T07:43:17.990054Z","iopub.status.idle":"2024-12-10T07:43:18.006197Z","shell.execute_reply.started":"2024-12-10T07:43:17.990009Z","shell.execute_reply":"2024-12-10T07:43:18.004823Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\n\n# Convert to DataFrame (if not already)\nX_train = pd.DataFrame(X_train)\ny_train = pd.Series(y_train)\n\n# Check for NaN values\nprint(\"NaN in X_train:\\n\", X_train.isnull().sum())\nprint(\"NaN in y_train:\\n\", y_train.isnull().sum())\n\n# Handle NaN values\nX_train.fillna(0, inplace=True)  # Replace NaN with 0 in features\ny_train.fillna(0, inplace=True)  # Replace NaN with 0 in target\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.007631Z","iopub.execute_input":"2024-12-10T07:43:18.007975Z","iopub.status.idle":"2024-12-10T07:43:18.102029Z","shell.execute_reply.started":"2024-12-10T07:43:18.007941Z","shell.execute_reply":"2024-12-10T07:43:18.100700Z"}},"outputs":[{"name":"stdout","text":"NaN in X_train:\n 0    0\ndtype: int64\nNaN in y_train:\n 0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from collections import Counter\n\n# Check class distribution\nprint(\"Class distribution in y_train:\", Counter(y_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.103613Z","iopub.execute_input":"2024-12-10T07:43:18.104000Z","iopub.status.idle":"2024-12-10T07:43:18.111609Z","shell.execute_reply.started":"2024-12-10T07:43:18.103951Z","shell.execute_reply":"2024-12-10T07:43:18.110197Z"}},"outputs":[{"name":"stdout","text":"Class distribution in y_train: Counter({0: 655, 1: 481, 2: 359})\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(\"y_train shape:\", y_train.shape)\n\n# Reshape y_train if necessary\nif len(y_train.shape) > 1:\n    y_train = y_train.ravel()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.113032Z","iopub.execute_input":"2024-12-10T07:43:18.113402Z","iopub.status.idle":"2024-12-10T07:43:18.128591Z","shell.execute_reply.started":"2024-12-10T07:43:18.113367Z","shell.execute_reply":"2024-12-10T07:43:18.127088Z"}},"outputs":[{"name":"stdout","text":"y_train shape: (1495,)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import numpy as np\n\n# Ensure X_train and y_train are NumPy arrays\nif not isinstance(X_train, np.ndarray):\n    X_train = np.array(X_train)\n\nif not isinstance(y_train, np.ndarray):\n    y_train = np.array(y_train)\n\n# Confirm their types\nprint(\"X_train type:\", type(X_train))\nprint(\"y_train type:\", type(y_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.129930Z","iopub.execute_input":"2024-12-10T07:43:18.130491Z","iopub.status.idle":"2024-12-10T07:43:18.146432Z","shell.execute_reply.started":"2024-12-10T07:43:18.130450Z","shell.execute_reply":"2024-12-10T07:43:18.144731Z"}},"outputs":[{"name":"stdout","text":"X_train type: <class 'numpy.ndarray'>\ny_train type: <class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(\"X_train dtype:\", X_train.dtype)\nprint(\"y_train dtype:\", y_train.dtype)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.147867Z","iopub.execute_input":"2024-12-10T07:43:18.148242Z","iopub.status.idle":"2024-12-10T07:43:18.167518Z","shell.execute_reply.started":"2024-12-10T07:43:18.148162Z","shell.execute_reply":"2024-12-10T07:43:18.166233Z"}},"outputs":[{"name":"stdout","text":"X_train dtype: object\ny_train dtype: int64\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\n\n# Convert X_train to numeric (if applicable)\nif X_train.dtype == 'object' or not np.issubdtype(X_train.dtype, np.number):\n    X_train = pd.DataFrame(X_train).apply(pd.to_numeric, errors='coerce').to_numpy()\n\n# Convert y_train to numeric (if applicable)\nif y_train.dtype == 'object' or not np.issubdtype(y_train.dtype, np.number):\n    y_train = pd.Series(y_train).apply(pd.to_numeric, errors='coerce').to_numpy()\n\nprint(\"Converted X_train dtype:\", X_train.dtype)\nprint(\"Converted y_train dtype:\", y_train.dtype)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.169127Z","iopub.execute_input":"2024-12-10T07:43:18.169766Z","iopub.status.idle":"2024-12-10T07:43:18.185130Z","shell.execute_reply.started":"2024-12-10T07:43:18.169713Z","shell.execute_reply":"2024-12-10T07:43:18.183856Z"}},"outputs":[{"name":"stdout","text":"Converted X_train dtype: object\nConverted y_train dtype: int64\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"X_train = np.nan_to_num(X_train, nan=0.0, posinf=1e9, neginf=-1e9)\ny_train = np.nan_to_num(y_train, nan=0, posinf=1e9, neginf=-1e9)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.186798Z","iopub.execute_input":"2024-12-10T07:43:18.187273Z","iopub.status.idle":"2024-12-10T07:43:18.203948Z","shell.execute_reply.started":"2024-12-10T07:43:18.187234Z","shell.execute_reply":"2024-12-10T07:43:18.202670Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"print(type(X_train))\nprint(X_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.205699Z","iopub.execute_input":"2024-12-10T07:43:18.206219Z","iopub.status.idle":"2024-12-10T07:43:18.222324Z","shell.execute_reply.started":"2024-12-10T07:43:18.206139Z","shell.execute_reply":"2024-12-10T07:43:18.221097Z"}},"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n(1495, 1)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\n\nif isinstance(X_train, csr_matrix):\n    X_train = X_train.toarray()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.224623Z","iopub.execute_input":"2024-12-10T07:43:18.225135Z","iopub.status.idle":"2024-12-10T07:43:18.236229Z","shell.execute_reply.started":"2024-12-10T07:43:18.225081Z","shell.execute_reply":"2024-12-10T07:43:18.234864Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import numpy as np\n\n# Ensure X_train is a 2D numpy array\nX_train = np.array(X_train)\n\n# Check for dimensional issues\nif len(X_train.shape) != 2:\n    raise ValueError(\"X_train must be a 2D array.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.237860Z","iopub.execute_input":"2024-12-10T07:43:18.238350Z","iopub.status.idle":"2024-12-10T07:43:18.250751Z","shell.execute_reply.started":"2024-12-10T07:43:18.238300Z","shell.execute_reply":"2024-12-10T07:43:18.249476Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"y_train = np.array(y_train).ravel()  # Flatten to 1D\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.256858Z","iopub.execute_input":"2024-12-10T07:43:18.257429Z","iopub.status.idle":"2024-12-10T07:43:18.264870Z","shell.execute_reply.started":"2024-12-10T07:43:18.257393Z","shell.execute_reply":"2024-12-10T07:43:18.263762Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"print(type(X_train))\nprint(X_train.shape)\nprint(X_train[:5])  # Display the first 5 rows for inspection\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.266305Z","iopub.execute_input":"2024-12-10T07:43:18.266762Z","iopub.status.idle":"2024-12-10T07:43:18.280726Z","shell.execute_reply.started":"2024-12-10T07:43:18.266713Z","shell.execute_reply":"2024-12-10T07:43:18.279217Z"}},"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n(1495, 1)\n[[<Compressed Sparse Row sparse matrix of dtype 'float64'\n  \twith 14 stored elements and shape (1, 1900)>          ]\n [<Compressed Sparse Row sparse matrix of dtype 'float64'\n  \twith 17 stored elements and shape (1, 1900)>          ]\n [<Compressed Sparse Row sparse matrix of dtype 'float64'\n  \twith 12 stored elements and shape (1, 1900)>          ]\n [<Compressed Sparse Row sparse matrix of dtype 'float64'\n  \twith 6 stored elements and shape (1, 1900)>           ]\n [<Compressed Sparse Row sparse matrix of dtype 'float64'\n  \twith 6 stored elements and shape (1, 1900)>           ]]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from scipy.sparse import vstack\n\n# Flatten the nested structure\nX_train_flat = vstack(X_train[:, 0])\n\nprint(\"Flattened X_train shape:\", X_train_flat.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.281935Z","iopub.execute_input":"2024-12-10T07:43:18.282460Z","iopub.status.idle":"2024-12-10T07:43:18.313509Z","shell.execute_reply.started":"2024-12-10T07:43:18.282421Z","shell.execute_reply":"2024-12-10T07:43:18.311966Z"}},"outputs":[{"name":"stdout","text":"Flattened X_train shape: (1495, 1900)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Convert the sparse matrix to dense format\nX_train_dense = X_train_flat.toarray()\n\n# Confirm the shape\nprint(\"Dense X_train shape:\", X_train_dense.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.315411Z","iopub.execute_input":"2024-12-10T07:43:18.315955Z","iopub.status.idle":"2024-12-10T07:43:18.355406Z","shell.execute_reply.started":"2024-12-10T07:43:18.315897Z","shell.execute_reply":"2024-12-10T07:43:18.353984Z"}},"outputs":[{"name":"stdout","text":"Dense X_train shape: (1495, 1900)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\n# Apply SMOTE\nsmote = SMOTE(random_state=42, k_neighbors=1)  # Adjust k_neighbors if necessary based on your data\nX_resampled, y_resampled = smote.fit_resample(X_train_dense, y_train)\n\n# Check the class distribution after resampling\nprint(\"Resampled class distribution:\", Counter(y_resampled))\nprint(\"Resampled X shape:\", X_resampled.shape)\nprint(\"Resampled y shape:\", y_resampled.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.356980Z","iopub.execute_input":"2024-12-10T07:43:18.357903Z","iopub.status.idle":"2024-12-10T07:43:18.555841Z","shell.execute_reply.started":"2024-12-10T07:43:18.357855Z","shell.execute_reply":"2024-12-10T07:43:18.553928Z"}},"outputs":[{"name":"stdout","text":"Resampled class distribution: Counter({2: 655, 1: 655, 0: 655})\nResampled X shape: (1965, 1900)\nResampled y shape: (1965,)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n    X_resampled, y_resampled, test_size=0.2, random_state=42\n)\n\nprint(\"Final training set shape:\", X_train_final.shape)\nprint(\"Final testing set shape:\", X_test_final.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.557437Z","iopub.execute_input":"2024-12-10T07:43:18.557921Z","iopub.status.idle":"2024-12-10T07:43:18.581333Z","shell.execute_reply.started":"2024-12-10T07:43:18.557882Z","shell.execute_reply":"2024-12-10T07:43:18.579158Z"}},"outputs":[{"name":"stdout","text":"Final training set shape: (1572, 1900)\nFinal testing set shape: (393, 1900)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_final)\nX_test_scaled = scaler.transform(X_test_final)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.583042Z","iopub.execute_input":"2024-12-10T07:43:18.583478Z","iopub.status.idle":"2024-12-10T07:43:18.649772Z","shell.execute_reply.started":"2024-12-10T07:43:18.583438Z","shell.execute_reply":"2024-12-10T07:43:18.648444Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train_scaled, y_train_final)\n\n# Evaluate on the test set\ntest_accuracy = model.score(X_test_scaled, y_test_final)\nprint(\"Test set accuracy:\", test_accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:18.651473Z","iopub.execute_input":"2024-12-10T07:43:18.651928Z","iopub.status.idle":"2024-12-10T07:43:20.761786Z","shell.execute_reply.started":"2024-12-10T07:43:18.651890Z","shell.execute_reply":"2024-12-10T07:43:20.760284Z"}},"outputs":[{"name":"stdout","text":"Test set accuracy: 0.5368956743002544\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# 7. Examples of Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### 7.1. Remove Irrelevant Features","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Train a Random Forest model\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train_scaled, y_train_final)\n\n# Extract feature importances\nimportances = rf_model.feature_importances_\nfeature_names = [f'Feature_{i}' for i in range(X_train_scaled.shape[1])]\n\n# Create a DataFrame for better visualization\nimportance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot feature importance\nplt.barh(importance_df['Feature'][:10], importance_df['Importance'][:10])\nplt.xlabel('Feature Importance')\nplt.title('Top 10 Features')\nplt.show()\n\n# Remove irrelevant features\nthreshold = 0.01  # Set importance threshold\nselected_features = importance_df[importance_df['Importance'] > threshold]['Feature']\nX_train_selected = X_train_scaled[:, :len(selected_features)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:20.763711Z","iopub.execute_input":"2024-12-10T07:43:20.764162Z","iopub.status.idle":"2024-12-10T07:43:23.089345Z","shell.execute_reply.started":"2024-12-10T07:43:20.764124Z","shell.execute_reply":"2024-12-10T07:43:23.087924Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"## 7.2. Add Interaction Terms","metadata":{}},{"cell_type":"code","source":"# Import PolynomialFeatures\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Select only the top 10 important features\nselected_indices = [1632, 1827, 48, 8, 1205, 786, 1339, 913, 979, 667]\nX_train_top_features = X_train_scaled[:, selected_indices]\n\n# Apply PolynomialFeatures to the selected features\npoly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\nX_train_interaction = poly.fit_transform(X_train_top_features)\n\n# Check the shape of the transformed data\nprint(\"Shape of transformed data:\", X_train_interaction.shape)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:23.091708Z","iopub.execute_input":"2024-12-10T07:43:23.092309Z","iopub.status.idle":"2024-12-10T07:43:23.103351Z","shell.execute_reply.started":"2024-12-10T07:43:23.092253Z","shell.execute_reply":"2024-12-10T07:43:23.101975Z"}},"outputs":[{"name":"stdout","text":"Shape of transformed data: (1572, 55)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"## 7.3. Reduce the Degree of Polynomial Expansion","metadata":{}},{"cell_type":"code","source":"poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\nX_train_interaction = poly.fit_transform(X_train_scaled)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:23.104683Z","iopub.execute_input":"2024-12-10T07:43:23.105232Z","iopub.status.idle":"2024-12-10T07:43:37.353537Z","shell.execute_reply.started":"2024-12-10T07:43:23.105153Z","shell.execute_reply":"2024-12-10T07:43:37.352198Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"selected_indices = [1632, 1827, 48, 8, 1205, 786, 1339, 913, 979, 667]  # Example indices\nX_train_top_features = X_train_scaled[:, selected_indices]\nX_train_interaction = poly.fit_transform(X_train_top_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:43:37.354947Z","iopub.execute_input":"2024-12-10T07:43:37.355320Z","iopub.status.idle":"2024-12-10T07:43:37.435279Z","shell.execute_reply.started":"2024-12-10T07:43:37.355285Z","shell.execute_reply":"2024-12-10T07:43:37.434199Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## 7.4. Incremental PCA","metadata":{}},{"cell_type":"code","source":"ipca = IncrementalPCA(n_components=min(55, 100))  # Adjust to min(features, target components)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:45:04.326215Z","iopub.execute_input":"2024-12-10T07:45:04.326692Z","iopub.status.idle":"2024-12-10T07:45:04.333041Z","shell.execute_reply.started":"2024-12-10T07:45:04.326654Z","shell.execute_reply":"2024-12-10T07:45:04.331628Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from sklearn.decomposition import IncrementalPCA\n\n# Select top features\nselected_indices = [1632, 1827, 48, 8, 1205, 786, 1339, 913, 979, 667]\nX_train_top_features = X_train_scaled[:, selected_indices]\n\n# Generate polynomial features\npoly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\nX_train_interaction = poly.fit_transform(X_train_top_features)\n\n# Apply Incremental PCA\nbatch_size = 100  # Set a batch size\nipca = IncrementalPCA(n_components=min(X_train_interaction.shape[1], 100))  # Adjust n_components\nfor batch in range(0, X_train_interaction.shape[0], batch_size):\n    ipca.partial_fit(X_train_interaction[batch:batch + batch_size])\n\n# Transform data\nX_train_reduced = ipca.transform(X_train_interaction)\nprint(\"Reduced feature shape:\", X_train_reduced.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:45:22.874248Z","iopub.execute_input":"2024-12-10T07:45:22.874701Z","iopub.status.idle":"2024-12-10T07:45:22.959047Z","shell.execute_reply.started":"2024-12-10T07:45:22.874660Z","shell.execute_reply":"2024-12-10T07:45:22.955771Z"}},"outputs":[{"name":"stdout","text":"Reduced feature shape: (1572, 55)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"print(\"Explained variance ratio (first 10 components):\", ipca.explained_variance_ratio_[:10])\nprint(\"Total variance explained by 55 components:\", np.sum(ipca.explained_variance_ratio_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:45:53.958723Z","iopub.execute_input":"2024-12-10T07:45:53.959415Z","iopub.status.idle":"2024-12-10T07:45:53.968208Z","shell.execute_reply.started":"2024-12-10T07:45:53.959367Z","shell.execute_reply":"2024-12-10T07:45:53.966315Z"}},"outputs":[{"name":"stdout","text":"Explained variance ratio (first 10 components): [0.0823131  0.07445059 0.07111956 0.0694513  0.06446726 0.0555831\n 0.05009575 0.04163673 0.03605906 0.03407461]\nTotal variance explained by 55 components: 0.9999999999999983\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"X_test_top_features = X_test_scaled[:, selected_indices]\nX_test_interaction = poly.transform(X_test_top_features)\nX_test_reduced = ipca.transform(X_test_interaction)\nprint(\"Reduced test set shape:\", X_test_reduced.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:46:10.199131Z","iopub.execute_input":"2024-12-10T07:46:10.199568Z","iopub.status.idle":"2024-12-10T07:46:10.213131Z","shell.execute_reply.started":"2024-12-10T07:46:10.199525Z","shell.execute_reply":"2024-12-10T07:46:10.209824Z"}},"outputs":[{"name":"stdout","text":"Reduced test set shape: (393, 55)\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"print(\"X_train_reduced shape:\", X_train_reduced.shape)\nprint(\"y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:47:09.218754Z","iopub.execute_input":"2024-12-10T07:47:09.219550Z","iopub.status.idle":"2024-12-10T07:47:09.228370Z","shell.execute_reply.started":"2024-12-10T07:47:09.219499Z","shell.execute_reply":"2024-12-10T07:47:09.226913Z"}},"outputs":[{"name":"stdout","text":"X_train_reduced shape: (1572, 55)\ny_train shape: (1495,)\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# Ensure y_train corresponds to X_train_reduced\nif len(y_train) != X_train_reduced.shape[0]:\n    print(\"Mismatch detected. Resyncing...\")\n    y_train = y_train[:X_train_reduced.shape[0]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:47:22.763712Z","iopub.execute_input":"2024-12-10T07:47:22.764255Z","iopub.status.idle":"2024-12-10T07:47:22.771534Z","shell.execute_reply.started":"2024-12-10T07:47:22.764211Z","shell.execute_reply":"2024-12-10T07:47:22.769986Z"}},"outputs":[{"name":"stdout","text":"Mismatch detected. Resyncing...\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"min_length = min(X_train_reduced.shape[0], len(y_train))\nX_train_reduced = X_train_reduced[:min_length]\ny_train = y_train[:min_length]\n\nprint(\"Aligned X_train_reduced shape:\", X_train_reduced.shape)\nprint(\"Aligned y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:48:01.054788Z","iopub.execute_input":"2024-12-10T07:48:01.055329Z","iopub.status.idle":"2024-12-10T07:48:01.062760Z","shell.execute_reply.started":"2024-12-10T07:48:01.055283Z","shell.execute_reply":"2024-12-10T07:48:01.061395Z"}},"outputs":[{"name":"stdout","text":"Aligned X_train_reduced shape: (1495, 55)\nAligned y_train shape: (1495,)\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"print(\"X_train_scaled shape:\", X_train_scaled.shape)\nprint(\"y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:48:56.679451Z","iopub.execute_input":"2024-12-10T07:48:56.680060Z","iopub.status.idle":"2024-12-10T07:48:56.687637Z","shell.execute_reply.started":"2024-12-10T07:48:56.680008Z","shell.execute_reply":"2024-12-10T07:48:56.686150Z"}},"outputs":[{"name":"stdout","text":"X_train_scaled shape: (1572, 1900)\ny_train shape: (1495,)\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"print(\"X_train_scaled shape:\", X_train_scaled.shape)\nprint(\"y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:49:22.464474Z","iopub.execute_input":"2024-12-10T07:49:22.464931Z","iopub.status.idle":"2024-12-10T07:49:22.471896Z","shell.execute_reply.started":"2024-12-10T07:49:22.464893Z","shell.execute_reply":"2024-12-10T07:49:22.470549Z"}},"outputs":[{"name":"stdout","text":"X_train_scaled shape: (1572, 1900)\ny_train shape: (1495,)\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"X_train_scaled = X_train_scaled[:y_train.shape[0]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:49:43.182438Z","iopub.execute_input":"2024-12-10T07:49:43.182898Z","iopub.status.idle":"2024-12-10T07:49:43.189158Z","shell.execute_reply.started":"2024-12-10T07:49:43.182861Z","shell.execute_reply":"2024-12-10T07:49:43.187566Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"print(\"Aligned X_train_scaled shape:\", X_train_scaled.shape)\nprint(\"Aligned y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:49:51.549304Z","iopub.execute_input":"2024-12-10T07:49:51.549729Z","iopub.status.idle":"2024-12-10T07:49:51.556508Z","shell.execute_reply.started":"2024-12-10T07:49:51.549695Z","shell.execute_reply":"2024-12-10T07:49:51.555079Z"}},"outputs":[{"name":"stdout","text":"Aligned X_train_scaled shape: (1495, 1900)\nAligned y_train shape: (1495,)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state=42, k_neighbors=1)  # Adjust k_neighbors if necessary\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n\nprint(\"Resampled X_train shape:\", X_train_resampled.shape)\nprint(\"Resampled y_train shape:\", y_train_resampled.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:50:17.859909Z","iopub.execute_input":"2024-12-10T07:50:17.860375Z","iopub.status.idle":"2024-12-10T07:50:17.991973Z","shell.execute_reply.started":"2024-12-10T07:50:17.860336Z","shell.execute_reply":"2024-12-10T07:50:17.990737Z"}},"outputs":[{"name":"stdout","text":"Resampled X_train shape: (1965, 1900)\nResampled y_train shape: (1965,)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"n_components = min(65, X_train_resampled.shape[1])  # Smallest batch size or number of features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:51:09.048768Z","iopub.execute_input":"2024-12-10T07:51:09.051126Z","iopub.status.idle":"2024-12-10T07:51:09.064369Z","shell.execute_reply.started":"2024-12-10T07:51:09.051040Z","shell.execute_reply":"2024-12-10T07:51:09.061992Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"from sklearn.decomposition import IncrementalPCA\n\nbatch_size = 100  # Adjust this based on available memory\nn_components = 65  # Adjusted to be less than or equal to the smallest batch size\n\nipca = IncrementalPCA(n_components=n_components)\nfor batch in range(0, X_train_resampled.shape[0], batch_size):\n    ipca.partial_fit(X_train_resampled[batch:batch+batch_size])\n\nX_train_reduced = ipca.transform(X_train_resampled)\nprint(\"Reduced X_train shape:\", X_train_reduced.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:51:19.305090Z","iopub.execute_input":"2024-12-10T07:51:19.305555Z","iopub.status.idle":"2024-12-10T07:51:20.690787Z","shell.execute_reply.started":"2024-12-10T07:51:19.305504Z","shell.execute_reply":"2024-12-10T07:51:20.686842Z"}},"outputs":[{"name":"stdout","text":"Reduced X_train shape: (1965, 65)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"X_test_reduced = ipca.transform(X_test_scaled)\nprint(\"Reduced X_test shape:\", X_test_reduced.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:51:42.018084Z","iopub.execute_input":"2024-12-10T07:51:42.018638Z","iopub.status.idle":"2024-12-10T07:51:42.040049Z","shell.execute_reply.started":"2024-12-10T07:51:42.018596Z","shell.execute_reply":"2024-12-10T07:51:42.036732Z"}},"outputs":[{"name":"stdout","text":"Reduced X_test shape: (393, 65)\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"# 8. Random Forrest Classifier Model","metadata":{}},{"cell_type":"code","source":"model.fit(X_train_reduced, y_train_resampled)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:52:03.517574Z","iopub.execute_input":"2024-12-10T07:52:03.518052Z","iopub.status.idle":"2024-12-10T07:52:05.099542Z","shell.execute_reply.started":"2024-12-10T07:52:03.518014Z","shell.execute_reply":"2024-12-10T07:52:05.097978Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"print(\"X_test_reduced shape:\", X_test_reduced.shape)\nprint(\"y_test shape:\", y_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:52:44.574073Z","iopub.execute_input":"2024-12-10T07:52:44.574548Z","iopub.status.idle":"2024-12-10T07:52:44.581118Z","shell.execute_reply.started":"2024-12-10T07:52:44.574513Z","shell.execute_reply":"2024-12-10T07:52:44.579545Z"}},"outputs":[{"name":"stdout","text":"X_test_reduced shape: (393, 65)\ny_test shape: (374, 3)\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n    y_test = np.argmax(y_test, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:53:13.657224Z","iopub.execute_input":"2024-12-10T07:53:13.657641Z","iopub.status.idle":"2024-12-10T07:53:13.663583Z","shell.execute_reply.started":"2024-12-10T07:53:13.657607Z","shell.execute_reply":"2024-12-10T07:53:13.662281Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"min_samples = min(X_test_reduced.shape[0], y_test.shape[0])\nX_test_reduced = X_test_reduced[:min_samples]\ny_test = y_test[:min_samples]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:53:57.811639Z","iopub.execute_input":"2024-12-10T07:53:57.812189Z","iopub.status.idle":"2024-12-10T07:53:57.818671Z","shell.execute_reply.started":"2024-12-10T07:53:57.812131Z","shell.execute_reply":"2024-12-10T07:53:57.817236Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"accuracy = model.score(X_test_reduced, y_test)\nprint(\"Model accuracy:\", accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:54:07.593275Z","iopub.execute_input":"2024-12-10T07:54:07.593706Z","iopub.status.idle":"2024-12-10T07:54:07.620987Z","shell.execute_reply.started":"2024-12-10T07:54:07.593666Z","shell.execute_reply":"2024-12-10T07:54:07.619742Z"}},"outputs":[{"name":"stdout","text":"Model accuracy: 0.3422459893048128\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"from collections import Counter\nprint(\"Training set label distribution:\", Counter(y_train_resampled))\nprint(\"Test set label distribution:\", Counter(y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:54:28.812628Z","iopub.execute_input":"2024-12-10T07:54:28.813055Z","iopub.status.idle":"2024-12-10T07:54:28.820400Z","shell.execute_reply.started":"2024-12-10T07:54:28.813017Z","shell.execute_reply":"2024-12-10T07:54:28.818961Z"}},"outputs":[{"name":"stdout","text":"Training set label distribution: Counter({2: 655, 1: 655, 0: 655})\nTest set label distribution: Counter({0: 187, 1: 113, 2: 74})\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred = model.predict(X_test_reduced)\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:56:03.986640Z","iopub.execute_input":"2024-12-10T07:56:03.987204Z","iopub.status.idle":"2024-12-10T07:56:04.026523Z","shell.execute_reply.started":"2024-12-10T07:56:03.987130Z","shell.execute_reply":"2024-12-10T07:56:04.025160Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.48      0.42      0.45       187\n           1       0.24      0.28      0.26       113\n           2       0.23      0.24      0.23        74\n\n    accuracy                           0.34       374\n   macro avg       0.32      0.31      0.31       374\nweighted avg       0.36      0.34      0.35       374\n\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"## 8.1. SMOTE","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state=42)\nX_test_balanced, y_test_balanced = smote.fit_resample(X_test_reduced, y_test)\n\ny_pred_balanced = model.predict(X_test_balanced)\nprint(classification_report(y_test_balanced, y_pred_balanced))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:56:33.814764Z","iopub.execute_input":"2024-12-10T07:56:33.815271Z","iopub.status.idle":"2024-12-10T07:56:33.864759Z","shell.execute_reply.started":"2024-12-10T07:56:33.815229Z","shell.execute_reply":"2024-12-10T07:56:33.863281Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.33      0.42      0.37       187\n           1       0.28      0.26      0.27       187\n           2       0.46      0.36      0.40       187\n\n    accuracy                           0.35       561\n   macro avg       0.35      0.35      0.35       561\nweighted avg       0.35      0.35      0.35       561\n\n","output_type":"stream"}],"execution_count":68},{"cell_type":"markdown","source":"# 9. XGBClassifier Model","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel = XGBClassifier(random_state=42, n_estimators=200, learning_rate=0.1)\nmodel.fit(X_train_reduced, y_train_resampled)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:57:06.488959Z","iopub.execute_input":"2024-12-10T07:57:06.489409Z","iopub.status.idle":"2024-12-10T07:57:12.544650Z","shell.execute_reply.started":"2024-12-10T07:57:06.489371Z","shell.execute_reply":"2024-12-10T07:57:12.543338Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n# Initialize XGBClassifier\nxgb_model = XGBClassifier(\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,  # Try different values for tuning\n    colsample_bytree=0.8,  # Random feature selection\n    subsample=0.8,  # Random row sampling\n    objective='multi:softprob',\n    random_state=42,\n    n_jobs=-1  # Use all available cores\n)\n\n# Train the model\nxgb_model.fit(X_train_reduced, y_train_resampled)\n\n# Predict on test data\ny_pred = xgb_model.predict(X_test_reduced)\n\n# Evaluate the model\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:57:57.894082Z","iopub.execute_input":"2024-12-10T07:57:57.894598Z","iopub.status.idle":"2024-12-10T07:58:02.917902Z","shell.execute_reply.started":"2024-12-10T07:57:57.894556Z","shell.execute_reply":"2024-12-10T07:58:02.916916Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.47      0.40      0.43       187\n           1       0.25      0.29      0.27       113\n           2       0.23      0.24      0.23        74\n\n    accuracy                           0.34       374\n   macro avg       0.31      0.31      0.31       374\nweighted avg       0.35      0.34      0.34       374\n\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Example model with class weights\nxgb_model = XGBClassifier(\n    scale_pos_weight={0: 1, 1: 2, 2: 2},  # Adjust weights for class imbalance\n    max_depth=6,\n    learning_rate=0.1,\n    n_estimators=200\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T07:58:58.978516Z","iopub.execute_input":"2024-12-10T07:58:58.979064Z","iopub.status.idle":"2024-12-10T07:58:58.986546Z","shell.execute_reply.started":"2024-12-10T07:58:58.979012Z","shell.execute_reply":"2024-12-10T07:58:58.985035Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"print(\"X_test_reduced shape:\", X_test_reduced.shape)\nprint(\"y_test shape:\", y_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:01:57.093390Z","iopub.execute_input":"2024-12-10T08:01:57.094051Z","iopub.status.idle":"2024-12-10T08:01:57.100939Z","shell.execute_reply.started":"2024-12-10T08:01:57.094005Z","shell.execute_reply":"2024-12-10T08:01:57.099702Z"}},"outputs":[{"name":"stdout","text":"X_test_reduced shape: (393, 65)\ny_test shape: (374,)\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"min_samples = min(X_test_reduced.shape[0], y_test.shape[0])\nX_test_reduced = X_test_reduced[:min_samples]\ny_test = y_test[:min_samples]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:03:29.188678Z","iopub.execute_input":"2024-12-10T08:03:29.189196Z","iopub.status.idle":"2024-12-10T08:03:29.195415Z","shell.execute_reply.started":"2024-12-10T08:03:29.189141Z","shell.execute_reply":"2024-12-10T08:03:29.194080Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"print(\"Aligned X_test_reduced shape:\", X_test_reduced.shape)\nprint(\"Aligned y_test shape:\", y_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:03:40.304244Z","iopub.execute_input":"2024-12-10T08:03:40.304739Z","iopub.status.idle":"2024-12-10T08:03:40.312077Z","shell.execute_reply.started":"2024-12-10T08:03:40.304700Z","shell.execute_reply":"2024-12-10T08:03:40.310498Z"}},"outputs":[{"name":"stdout","text":"Aligned X_test_reduced shape: (374, 65)\nAligned y_test shape: (374,)\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Predict on the reduced test set\ny_pred = xgb_model.predict(X_test_reduced)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Model accuracy on reduced features:\", accuracy)\n\n# Generate and print a classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:04:08.435267Z","iopub.execute_input":"2024-12-10T08:04:08.435767Z","iopub.status.idle":"2024-12-10T08:04:08.464888Z","shell.execute_reply.started":"2024-12-10T08:04:08.435726Z","shell.execute_reply":"2024-12-10T08:04:08.463795Z"}},"outputs":[{"name":"stdout","text":"Model accuracy on reduced features: 0.3342245989304813\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.47      0.42      0.44       187\n           1       0.24      0.23      0.23       113\n           2       0.21      0.28      0.24        74\n\n    accuracy                           0.33       374\n   macro avg       0.31      0.31      0.31       374\nweighted avg       0.35      0.33      0.34       374\n\n","output_type":"stream"}],"execution_count":79},{"cell_type":"markdown","source":"# Second Attempt","metadata":{}},{"cell_type":"markdown","source":"##  Import Libraries and Align Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom xgboost import XGBClassifier\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectFromModel\n\n# Ensure data is aligned\nX_train_scaled, y_train = X_train_scaled[:len(y_train)], y_train\nX_test_reduced, y_test = X_test_reduced[:len(y_test)], y_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:07:27.602553Z","iopub.execute_input":"2024-12-10T08:07:27.604137Z","iopub.status.idle":"2024-12-10T08:07:27.633529Z","shell.execute_reply.started":"2024-12-10T08:07:27.604072Z","shell.execute_reply":"2024-12-10T08:07:27.632478Z"}},"outputs":[],"execution_count":80},{"cell_type":"markdown","source":"## Handle Class Imbalance","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\nprint(\"Class distribution before resampling:\", Counter(y_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:08:31.213897Z","iopub.execute_input":"2024-12-10T08:08:31.214364Z","iopub.status.idle":"2024-12-10T08:08:31.221874Z","shell.execute_reply.started":"2024-12-10T08:08:31.214323Z","shell.execute_reply":"2024-12-10T08:08:31.220388Z"}},"outputs":[{"name":"stdout","text":"Class distribution before resampling: Counter({0: 655, 1: 481, 2: 359})\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"from collections import Counter\nprint(\"Class distribution before ADASYN:\", Counter(y_train))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:09:40.207791Z","iopub.execute_input":"2024-12-10T08:09:40.208270Z","iopub.status.idle":"2024-12-10T08:09:40.215696Z","shell.execute_reply.started":"2024-12-10T08:09:40.208229Z","shell.execute_reply":"2024-12-10T08:09:40.214153Z"}},"outputs":[{"name":"stdout","text":"Class distribution before ADASYN: Counter({0: 655, 1: 481, 2: 359})\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"from imblearn.over_sampling import ADASYN\nfrom collections import Counter\n\n# Check original class distribution\nprint(\"Class distribution before ADASYN:\", Counter(y_train))\n\n# Define the target sampling strategy with higher target counts for minority classes\nsampling_strategy = {0: 655, 1: 700, 2: 700}  # Increase targets for classes 1 and 2\n\n# Apply ADASYN\nadasyn = ADASYN(sampling_strategy=sampling_strategy, random_state=42)\ntry:\n    X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_scaled, y_train)\n    # Check the new class distribution\n    print(\"Class distribution after ADASYN:\", Counter(y_train_adasyn))\nexcept ValueError as e:\n    print(\"Error during ADASYN resampling:\", e)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:11:10.724145Z","iopub.execute_input":"2024-12-10T08:11:10.725116Z","iopub.status.idle":"2024-12-10T08:11:11.230829Z","shell.execute_reply.started":"2024-12-10T08:11:10.725032Z","shell.execute_reply":"2024-12-10T08:11:11.229459Z"}},"outputs":[{"name":"stdout","text":"Class distribution before ADASYN: Counter({0: 655, 1: 481, 2: 359})\nClass distribution after ADASYN: Counter({2: 713, 0: 655, 1: 605})\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"model.fit(X_train_adasyn, y_train_adasyn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:12:19.932278Z","iopub.execute_input":"2024-12-10T08:12:19.932935Z","iopub.status.idle":"2024-12-10T08:12:25.072730Z","shell.execute_reply.started":"2024-12-10T08:12:19.932888Z","shell.execute_reply":"2024-12-10T08:12:25.071687Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=200, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"X_test_scaled = X_test_scaled[:len(y_test)]  # Align X_test_scaled with the size of y_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:13:30.700823Z","iopub.execute_input":"2024-12-10T08:13:30.701366Z","iopub.status.idle":"2024-12-10T08:13:30.710491Z","shell.execute_reply.started":"2024-12-10T08:13:30.701321Z","shell.execute_reply":"2024-12-10T08:13:30.707830Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"# Step 1: Train the model on the ADASYN-resampled data\nxgb_model = XGBClassifier(\n    n_estimators=200,\n    learning_rate=0.1,\n    objective='multi:softmax',\n    random_state=42\n)\nxgb_model.fit(X_train_adasyn, y_train_adasyn)\n\n# Step 2: Make predictions on the test set\ny_test_pred = xgb_model.predict(X_test_scaled)\n\n# Step 3: Evaluate the model's performance\nfrom sklearn.metrics import classification_report, accuracy_score\n\naccuracy = accuracy_score(y_test, y_test_pred)\nprint(\"Model accuracy on test set:\", accuracy)\n\n# Generate a detailed classification report\nreport = classification_report(y_test, y_test_pred, target_names=['Class 0', 'Class 1', 'Class 2'])\nprint(\"\\nClassification Report:\\n\", report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:13:48.032995Z","iopub.execute_input":"2024-12-10T08:13:48.034209Z","iopub.status.idle":"2024-12-10T08:13:54.524724Z","shell.execute_reply.started":"2024-12-10T08:13:48.034129Z","shell.execute_reply":"2024-12-10T08:13:54.522863Z"}},"outputs":[{"name":"stdout","text":"Model accuracy on test set: 0.32620320855614976\n\nClassification Report:\n               precision    recall  f1-score   support\n\n     Class 0       0.49      0.37      0.42       187\n     Class 1       0.28      0.25      0.26       113\n     Class 2       0.18      0.32      0.23        74\n\n    accuracy                           0.33       374\n   macro avg       0.32      0.32      0.31       374\nweighted avg       0.37      0.33      0.34       374\n\n","output_type":"stream"}],"execution_count":91},{"cell_type":"markdown","source":"Recommendations:\nFeature Engineering:\n\nCheck for irrelevant features and consider feature selection or dimensionality reduction techniques (PCA, IncrementalPCA).\nExperiment with adding interaction terms to capture relationships between features.\nHyperparameter Tuning:\n\nUse a grid search or random search to optimize XGBClassifier hyperparameters such as max_depth, min_child_weight, learning_rate, and subsample.\nEnable scale_pos_weight for handling class imbalance directly in the XGBoost model.\nAdditional Resampling Techniques:\n\nTry other oversampling methods (e.g., SMOTEENN) or undersampling to address the imbalance in a different way.\nUse RandomOverSampler combined with SMOTE to explore oversampling strategies.\nModel Selection:\n\nExperiment with different algorithms like Random Forest, LightGBM, or SVM to see if they perform better on your data.\nCross-validation:\n\nImplement stratified k-fold cross-validation to ensure that the evaluation results are robust and not specific to one test split.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Define parameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 5, 7],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'subsample': [0.8, 1.0],\n    'colsample_bytree': [0.8, 1.0]\n}\n\n# Initialize Grid Search\ngrid_search = GridSearchCV(\n    estimator=XGBClassifier(objective='multi:softmax', random_state=42),\n    param_grid=param_grid,\n    scoring='accuracy',\n    cv=3,\n    verbose=2,\n    n_jobs=-1\n)\n\n# Fit Grid Search\ngrid_search.fit(X_train_adasyn, y_train_adasyn)\n\n# Best Parameters\nprint(\"Best parameters:\", grid_search.best_params_)\n\n# Evaluate on Test Set\nbest_model = grid_search.best_estimator_\ny_test_pred = best_model.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_test_pred)\nprint(\"Optimized Model Accuracy:\", accuracy)\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:15:52.113829Z","iopub.execute_input":"2024-12-10T08:15:52.114440Z","iopub.status.idle":"2024-12-10T08:26:33.516104Z","shell.execute_reply.started":"2024-12-10T08:15:52.114392Z","shell.execute_reply":"2024-12-10T08:26:33.514248Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 108 candidates, totalling 324 fits\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   4.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   4.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   4.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   3.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.4s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  11.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  11.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  11.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   6.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   6.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=  11.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=  10.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=  10.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=  11.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=  10.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=  10.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=  15.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=  14.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=  14.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=  16.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=  15.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=  14.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.4s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.4s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   7.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   9.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   9.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.4s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   6.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   6.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   4.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   4.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   4.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   4.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   8.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   8.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   8.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   8.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  13.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  13.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  13.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  13.4s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  12.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  13.4s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   7.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   7.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   7.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   3.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   3.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   3.6s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   6.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   6.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   6.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   6.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   6.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.4s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   9.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=   9.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   4.9s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   4.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.3s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   8.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.2s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   8.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=   8.5s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8; total time=  13.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8; total time=  13.1s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0; total time=  12.7s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8; total time=  13.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.0s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0; total time=  12.8s\n[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0; total time=  13.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   9.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  12.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  13.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   6.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  12.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=  11.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   6.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=  11.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=  10.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=  11.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=  12.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=  10.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=  11.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=  17.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=  16.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8; total time=  15.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=  17.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   3.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=  16.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=  15.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   6.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   6.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   7.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.0s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   3.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   3.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.6s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   9.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=  10.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=  10.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   9.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  14.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  14.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8; total time=  14.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  13.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  13.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8; total time=   2.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0; total time=  13.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   3.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   2.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   5.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.8; total time=   6.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   5.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.8; total time=   8.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=1.0; total time=   8.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   4.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   3.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=1.0; total time=   4.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   8.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   7.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   8.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=1.0; total time=   7.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  11.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=  10.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   5.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.5s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=1.0; total time=  10.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=0.8; total time=   4.9s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   4.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   5.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=100, subsample=1.0; total time=   4.8s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=  10.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=  10.3s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.8; total time=   9.7s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=  10.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=  10.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=1.0; total time=  10.1s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8; total time=  16.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8; total time=  16.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0; total time=  15.4s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=0.8; total time=  16.0s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0; total time=  13.2s\n[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=300, subsample=1.0; total time=  14.1s\nBest parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\nOptimized Model Accuracy: 0.3422459893048128\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.51      0.41      0.46       187\n           1       0.30      0.32      0.31       113\n           2       0.15      0.20      0.17        74\n\n    accuracy                           0.34       374\n   macro avg       0.32      0.31      0.31       374\nweighted avg       0.38      0.34      0.35       374\n\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"This code snippet performs hyperparameter tuning on an XGBoost classifier using GridSearchCV to find the best combination of parameters (like the number of estimators, maximum depth, learning rate, subsample ratio, and column sampling ratio) for a multi-class classification task. The grid search evaluates different parameter combinations through cross-validation (cv=3) to optimize accuracy. After finding the best parameters, the model is evaluated on the test dataset, providing metrics such as accuracy, precision, recall, and F1-score. Despite optimization, the performance remains modest, indicating possible limitations in data quality, feature selection, or model complexity.","metadata":{}},{"cell_type":"markdown","source":"## SMOTEENN Sampling:","metadata":{}},{"cell_type":"code","source":"from imblearn.combine import SMOTEENN\n\n# Combine SMOTE with Edited Nearest Neighbors (ENN)\nsmoteenn = SMOTEENN(random_state=42)\nX_train_smoteenn, y_train_smoteenn = smoteenn.fit_resample(X_train_scaled, y_train)\n\n# Check distribution\nfrom collections import Counter\nprint(\"Class distribution after SMOTEENN:\", Counter(y_train_smoteenn))\n\n# Train and evaluate the model\nxgb_model.fit(X_train_smoteenn, y_train_smoteenn)\ny_test_pred = xgb_model.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_test_pred)\nprint(\"SMOTEENN Model Accuracy:\", accuracy)\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:28:29.431001Z","iopub.execute_input":"2024-12-10T08:28:29.431681Z","iopub.status.idle":"2024-12-10T08:28:32.347722Z","shell.execute_reply.started":"2024-12-10T08:28:29.431622Z","shell.execute_reply":"2024-12-10T08:28:32.346764Z"}},"outputs":[{"name":"stdout","text":"Class distribution after SMOTEENN: Counter({2: 186, 1: 58, 0: 35})\nSMOTEENN Model Accuracy: 0.23796791443850268\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.48      0.12      0.19       187\n           1       0.28      0.13      0.18       113\n           2       0.19      0.70      0.30        74\n\n    accuracy                           0.24       374\n   macro avg       0.32      0.32      0.22       374\nweighted avg       0.36      0.24      0.21       374\n\n","output_type":"stream"}],"execution_count":94},{"cell_type":"markdown","source":"The results indicate that applying SMOTEENN, a hybrid technique combining SMOTE (oversampling) and Edited Nearest Neighbors (undersampling), has significantly altered the class distribution and resulted in poor performance on the test dataset. The class distribution is now heavily skewed, with class 2 dominating, and the model's overall accuracy has dropped to 23.8%. The classification report shows a sharp imbalance in precision, recall, and F1-scores, with class 2 achieving a high recall but very low precision, while the other classes suffer from poor recall and precision. These results suggest that SMOTEENN may not be suitable for the given dataset, as it creates an imbalance detrimental to the model's predictive performance. Further adjustments or alternative resampling strategies may be needed to improve the results.","metadata":{}},{"cell_type":"markdown","source":"# Third attempt","metadata":{}},{"cell_type":"markdown","source":"## 1. Feature Selection Using Recursive Feature Elimination (RFE)","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Use RFE for feature selection\nrfe_selector = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=50, step=10)\nX_train_rfe = rfe_selector.fit_transform(X_train_scaled, y_train)\nX_test_rfe = rfe_selector.transform(X_test_scaled)\n\nprint(\"Selected features shape:\", X_train_rfe.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:31:17.604136Z","iopub.execute_input":"2024-12-10T08:31:17.605817Z","iopub.status.idle":"2024-12-10T08:36:29.552431Z","shell.execute_reply.started":"2024-12-10T08:31:17.605752Z","shell.execute_reply":"2024-12-10T08:36:29.551008Z"}},"outputs":[{"name":"stdout","text":"Selected features shape: (1495, 50)\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"## 2. Stratified Splitting","metadata":{}},{"cell_type":"code","source":"# Check for NaN values in y\nimport numpy as np\n\nprint(\"Number of NaN values in y:\", np.isnan(y).sum())\n\n# Handle NaN values: Remove rows or impute values\n# Example: Removing rows with NaN in y\nvalid_indices = ~np.isnan(y)\nX = X[valid_indices]\ny = y[valid_indices]\n\nprint(\"After removing NaN values:\")\nprint(\"X shape:\", X.shape)\nprint(\"y shape:\", y.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:37:43.054625Z","iopub.execute_input":"2024-12-10T08:37:43.055123Z","iopub.status.idle":"2024-12-10T08:37:43.069690Z","shell.execute_reply.started":"2024-12-10T08:37:43.055078Z","shell.execute_reply":"2024-12-10T08:37:43.068491Z"}},"outputs":[{"name":"stdout","text":"Number of NaN values in y: MisconceptionAId    734\nMisconceptionBId    751\nMisconceptionCId    789\ndtype: int64\nAfter removing NaN values:\nX shape: (1, 3333)\ny shape: (1869, 3)\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"# If y is one-hot encoded, we can convert it to a single target column\ny_single = np.argmax(y, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:39:10.642771Z","iopub.execute_input":"2024-12-10T08:39:10.643285Z","iopub.status.idle":"2024-12-10T08:39:10.650221Z","shell.execute_reply.started":"2024-12-10T08:39:10.643243Z","shell.execute_reply":"2024-12-10T08:39:10.648958Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"# Ensure y is in a suitable format for multi-label classification\nfrom sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\ny_multi = mlb.fit_transform(y)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:39:22.962703Z","iopub.execute_input":"2024-12-10T08:39:22.963119Z","iopub.status.idle":"2024-12-10T08:39:22.970397Z","shell.execute_reply.started":"2024-12-10T08:39:22.963085Z","shell.execute_reply":"2024-12-10T08:39:22.968920Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"# Ensure y_single has the correct shape (should be 1D with the same number of samples as X)\ny_single = np.argmax(y, axis=1)  # If your original y was one-hot encoded\nprint(\"Shape of y_single:\", y_single.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:40:23.164412Z","iopub.execute_input":"2024-12-10T08:40:23.164918Z","iopub.status.idle":"2024-12-10T08:40:23.172958Z","shell.execute_reply.started":"2024-12-10T08:40:23.164877Z","shell.execute_reply":"2024-12-10T08:40:23.171488Z"}},"outputs":[{"name":"stdout","text":"Shape of y_single: (1869,)\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"print(f\"X shape before fixing: {X.shape}\")\n# If necessary, reshape or reprocess X so it has the same number of samples as y_single\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:41:32.763643Z","iopub.execute_input":"2024-12-10T08:41:32.764128Z","iopub.status.idle":"2024-12-10T08:41:32.772022Z","shell.execute_reply.started":"2024-12-10T08:41:32.764078Z","shell.execute_reply":"2024-12-10T08:41:32.770291Z"}},"outputs":[{"name":"stdout","text":"X shape before fixing: (1, 3333)\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"import numpy as np\n\n# Create an example dataset with 1869 samples and 3333 features (adjust this part to your actual dataset)\nX = np.random.rand(1869, 3333)\n\nprint(f\"Fixed X shape: {X.shape}\")  # Expected: (1869, 3333)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:43:17.551707Z","iopub.execute_input":"2024-12-10T08:43:17.552209Z","iopub.status.idle":"2024-12-10T08:43:17.622406Z","shell.execute_reply.started":"2024-12-10T08:43:17.552137Z","shell.execute_reply":"2024-12-10T08:43:17.621034Z"}},"outputs":[{"name":"stdout","text":"Fixed X shape: (1869, 3333)\n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"print(f\"Shape of y_single: {y_single.shape}\")  # Expected: (1869,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:43:41.039212Z","iopub.execute_input":"2024-12-10T08:43:41.039835Z","iopub.status.idle":"2024-12-10T08:43:41.047510Z","shell.execute_reply.started":"2024-12-10T08:43:41.039785Z","shell.execute_reply":"2024-12-10T08:43:41.045608Z"}},"outputs":[{"name":"stdout","text":"Shape of y_single: (1869,)\n","output_type":"stream"}],"execution_count":108},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\n# Perform Stratified Shuffle Split\nstrat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in strat_split.split(X, y_single):\n    X_train_strat, X_test_strat = X[train_index], X[test_index]\n    y_train_strat, y_test_strat = y_single[train_index], y_single[test_index]\n\n# Print the shapes to verify\nprint(\"X_train_strat shape:\", X_train_strat.shape)\nprint(\"X_test_strat shape:\", X_test_strat.shape)\nprint(\"y_train_strat shape:\", y_train_strat.shape)\nprint(\"y_test_strat shape:\", y_test_strat.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:44:16.816908Z","iopub.execute_input":"2024-12-10T08:44:16.817398Z","iopub.status.idle":"2024-12-10T08:44:16.848738Z","shell.execute_reply.started":"2024-12-10T08:44:16.817358Z","shell.execute_reply":"2024-12-10T08:44:16.846948Z"}},"outputs":[{"name":"stdout","text":"X_train_strat shape: (1495, 3333)\nX_test_strat shape: (374, 3333)\ny_train_strat shape: (1495,)\ny_test_strat shape: (374,)\n","output_type":"stream"}],"execution_count":109},{"cell_type":"markdown","source":"## 3. XGB Classifier Model","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize the XGBoost model\nxgb_model = XGBClassifier(objective='multi:softmax', random_state=42)\n\n# Train the model\nxgb_model.fit(X_train_strat, y_train_strat)\n\n# Predict on the test set\ny_test_pred = xgb_model.predict(X_test_strat)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test_strat, y_test_pred)\nprint(f\"Model accuracy: {accuracy}\")\n\n# Print classification report for detailed performance metrics\nprint(\"\\nClassification Report:\\n\", classification_report(y_test_strat, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:44:43.689736Z","iopub.execute_input":"2024-12-10T08:44:43.690201Z","iopub.status.idle":"2024-12-10T08:46:18.696264Z","shell.execute_reply.started":"2024-12-10T08:44:43.690147Z","shell.execute_reply":"2024-12-10T08:46:18.695112Z"}},"outputs":[{"name":"stdout","text":"Model accuracy: 0.41711229946524064\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.45      0.78      0.57       168\n           1       0.30      0.18      0.22       119\n           2       0.40      0.05      0.08        87\n\n    accuracy                           0.42       374\n   macro avg       0.38      0.33      0.29       374\nweighted avg       0.39      0.42      0.34       374\n\n","output_type":"stream"}],"execution_count":110},{"cell_type":"markdown","source":"The results indicate that the model is performing moderately well, but there is room for improvement, especially with the minority classes. Here's a summary of the output:\n\nOverall Accuracy: 41.7%\nPrecision for Class 0: 45% (Good recall)\nPrecision for Class 1: 30% (Moderate recall)\nPrecision for Class 2: 40% (Low recall)\nRecall for Class 0: 78% (Good for majority class)\nRecall for Class 1 and Class 2: Much lower, especially for Class 2 (5% recall), indicating an imbalance problem.\nNext Steps to Improve Model:\nHandle Class Imbalance:\n\nTry SMOTE: If not already done, consider using SMOTE for oversampling the minority classes.\nClass Weight Adjustment: Adjust the scale_pos_weight in XGBoost to balance the contribution of each class.\nHyperparameter Tuning:\n\nConduct a Grid Search or Randomized Search over hyperparameters (learning_rate, max_depth, n_estimators, etc.) to find the optimal model settings.\nFeature Engineering:\n\nConsider feature selection or using different transformations to extract more informative features.\nTry Other Models:\n\nTry different models like RandomForest, LightGBM, or Logistic Regression to compare their performance.\nPost-processing:\n\nApply class thresholding techniques for better performance on imbalanced datasets.","metadata":{}},{"cell_type":"code","source":"## 1. Handling Class Imbalance with SMOTE","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Apply SMOTE for oversampling the minority classes\nsmote = SMOTE(random_state=42)\nX_train_smote, y_train_smote = smote.fit_resample(X_train_strat, y_train_strat)\n\n# Check the class distribution after SMOTE\nfrom collections import Counter\nprint(\"Class distribution after SMOTE:\", Counter(y_train_smote))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:48:20.105533Z","iopub.execute_input":"2024-12-10T08:48:20.107646Z","iopub.status.idle":"2024-12-10T08:48:20.257375Z","shell.execute_reply.started":"2024-12-10T08:48:20.107523Z","shell.execute_reply":"2024-12-10T08:48:20.255905Z"}},"outputs":[{"name":"stdout","text":"Class distribution after SMOTE: Counter({1: 674, 2: 674, 0: 674})\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Train XGBoost on the balanced dataset (SMOTE)\nxgb_model = XGBClassifier(objective='multi:softmax', random_state=42)\nxgb_model.fit(X_train_smote, y_train_smote)\n\n# Evaluate on the test set\ny_test_pred = xgb_model.predict(X_test_strat)\naccuracy = accuracy_score(y_test_strat, y_test_pred)\nprint(\"Model accuracy on test set:\", accuracy)\n\n# Generate a classification report\nprint(\"\\nClassification Report:\\n\", classification_report(y_test_strat, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:49:07.895738Z","iopub.execute_input":"2024-12-10T08:49:07.896195Z","iopub.status.idle":"2024-12-10T08:50:52.956674Z","shell.execute_reply.started":"2024-12-10T08:49:07.896137Z","shell.execute_reply":"2024-12-10T08:50:52.953984Z"}},"outputs":[{"name":"stdout","text":"Model accuracy on test set: 0.3850267379679144\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.45      0.67      0.54       168\n           1       0.28      0.20      0.24       119\n           2       0.19      0.08      0.11        87\n\n    accuracy                           0.39       374\n   macro avg       0.31      0.32      0.30       374\nweighted avg       0.34      0.39      0.34       374\n\n","output_type":"stream"}],"execution_count":112},{"cell_type":"markdown","source":"## 2. Adjust Class Weights for XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Define XGB model with adjusted class weights\nxgb_model = XGBClassifier(\n    objective='multi:softmax',\n    random_state=42,\n    scale_pos_weight={0: 1, 1: 3, 2: 3}  # Adjust for class imbalance\n)\n\n# Train the model\nxgb_model.fit(X_train_smote, y_train_smote)\n\n# Evaluate on the test set\ny_test_pred = xgb_model.predict(X_test_strat)\naccuracy = accuracy_score(y_test_strat, y_test_pred)\nprint(\"Model accuracy on test set:\", accuracy)\n\n# Generate a detailed classification report\nfrom sklearn.metrics import classification_report\nprint(\"\\nClassification Report:\\n\", classification_report(y_test_strat, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:55:25.410962Z","iopub.execute_input":"2024-12-10T08:55:25.411543Z","iopub.status.idle":"2024-12-10T08:57:08.958878Z","shell.execute_reply.started":"2024-12-10T08:55:25.411497Z","shell.execute_reply":"2024-12-10T08:57:08.954965Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [08:55:26] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"scale_pos_weight\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Model accuracy on test set: 0.3850267379679144\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.45      0.67      0.54       168\n           1       0.28      0.20      0.24       119\n           2       0.19      0.08      0.11        87\n\n    accuracy                           0.39       374\n   macro avg       0.31      0.32      0.30       374\nweighted avg       0.34      0.39      0.34       374\n\n","output_type":"stream"}],"execution_count":113},{"cell_type":"markdown","source":"The results of the XGBoost model show a test set accuracy of 0.39, with Class 0 performing significantly better than Class 1 and Class 2 in terms of precision and recall. Here's a brief breakdown of what the classification report tells us:\n\nClass 0: Better performance with 0.67 recall and 0.54 f1-score, indicating that the model does a decent job of identifying Class 0, though still with room for improvement.\nClass 1: Lower performance with 0.20 recall and 0.24 f1-score, suggesting the model struggles to correctly classify this class.\nClass 2: Very low recall (0.08) and f1-score (0.11), indicating significant underperformance in identifying Class 2.\nPotential Areas for Improvement:\nClass Imbalance: The model is still affected by the imbalance between classes. While you've applied SMOTE to balance the classes, the results suggest that more aggressive or different techniques (like SMOTEENN or ADASYN) could potentially work better.\nModel Tuning: Experimenting with hyperparameter tuning (e.g., using GridSearchCV or RandomizedSearchCV) could yield better results, especially adjusting learning rate, depth, and other parameters.\nFeature Engineering: Consider adding more meaningful features or using dimensionality reduction techniques like PCA or TSNE to help the model generalize better.\nAlternative Models: If XGBoost continues to underperform, trying LightGBM, RandomForestClassifier, or Neural Networks might provide different insights or improvements.","metadata":{}},{"cell_type":"markdown","source":"## 3. Hyperparameter Tuning with GridSearchCV","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Define parameter grid for tuning\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 5, 7],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'subsample': [0.8, 1.0],\n    'colsample_bytree': [0.8, 1.0]\n}\n\n# Initialize Grid Search\ngrid_search = GridSearchCV(\n    estimator=XGBClassifier(objective='multi:softmax', random_state=42),\n    param_grid=param_grid,\n    scoring='accuracy',\n    cv=3,\n    verbose=2,\n    n_jobs=-1\n)\n\n# Fit Grid Search\ngrid_search.fit(X_train_smote, y_train_smote)\n\n# Best Parameters\nprint(\"Best parameters found:\", grid_search.best_params_)\n\n# Get the best model and evaluate on the test set\nbest_model = grid_search.best_estimator_\ny_test_pred = best_model.predict(X_test_strat)\naccuracy = accuracy_score(y_test_strat, y_test_pred)\nprint(\"Optimized Model Accuracy:\", accuracy)\n\n# Classification report for the optimized model\nprint(\"\\nClassification Report for Optimized Model:\\n\", classification_report(y_test_strat, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:58:09.918620Z","iopub.execute_input":"2024-12-10T08:58:09.919085Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 108 candidates, totalling 324 fits\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time= 1.5min\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time= 1.5min\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time= 1.5min\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time= 1.5min\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time= 1.5min\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time= 1.5min\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time= 3.0min\n[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time= 3.0min\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## 4. Feature Engineering: Feature Selection","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_classif\n\n# Select the top 50 features using SelectKBest\nselector = SelectKBest(f_classif, k=50)\nX_train_selected = selector.fit_transform(X_train_smote, y_train_smote)\n\n# Check selected features\nprint(f\"Selected features shape: {X_train_selected.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Try Other Models: Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Initialize and train a Random Forest model\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train_smote, y_train_smote)\n\n# Evaluate on the test set\ny_test_pred_rf = rf_model.predict(X_test_strat)\naccuracy_rf = accuracy_score(y_test_strat, y_test_pred_rf)\nprint(\"Random Forest Model Accuracy:\", accuracy_rf)\n\n# Generate classification report for Random Forest\nprint(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test_strat, y_test_pred_rf))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Post-processing: Class Thresholding","metadata":{}},{"cell_type":"code","source":"# Applying class thresholding to adjust the decision boundary for better recall on the minority class\n# Here, the threshold is adjusted manually for better performance\nthreshold = 0.3  # You can adjust this based on your use case\n\ny_prob = best_model.predict_proba(X_test_strat)\ny_test_pred_threshold = (y_prob[:, 2] > threshold).astype(int)  # Class 2 as an example\n\n# Evaluate performance after thresholding\naccuracy_threshold = accuracy_score(y_test_strat, y_test_pred_threshold)\nprint(\"Accuracy after thresholding:\", accuracy_threshold)\n\n# Classification report after thresholding\nprint(\"\\nClassification Report after Thresholding:\\n\", classification_report(y_test_strat, y_test_pred_threshold))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Final Model: Evaluate All","metadata":{}},{"cell_type":"code","source":"# Final evaluation after all improvements\nfinal_model = best_model  # or use the model that performed best during tuning\n\n# Predict on the test set\ny_test_pred_final = final_model.predict(X_test_strat)\nfinal_accuracy = accuracy_score(y_test_strat, y_test_pred_final)\nprint(\"Final Model Accuracy:\", final_accuracy)\n\n# Final classification report\nprint(\"\\nFinal Model Classification Report:\\n\", classification_report(y_test_strat, y_test_pred_final))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train the Model with LightGBM","metadata":{}},{"cell_type":"code","source":"pip install lightgbm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Train LightGBM on the balanced dataset (SMOTE)\nlgb_model = lgb.LGBMClassifier(objective='multiclass', num_class=3, random_state=42)\nlgb_model.fit(X_train_smote, y_train_smote)\n\n# Evaluate on the test set\ny_test_pred_lgb = lgb_model.predict(X_test_strat)\naccuracy_lgb = accuracy_score(y_test_strat, y_test_pred_lgb)\nprint(\"LGBM Model accuracy on test set:\", accuracy_lgb)\n\n# Generate a classification report\nprint(\"\\nLGBM Classification Report:\\n\", classification_report(y_test_strat, y_test_pred_lgb))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameter Tuning with GridSearchCV","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Define parameter grid for LGBM\nparam_grid = {\n    'num_leaves': [31, 50, 100],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 5, 7],\n}\n\n# Initialize Grid Search for LGBM\ngrid_search = GridSearchCV(\n    estimator=lgb.LGBMClassifier(objective='multiclass', num_class=3, random_state=42),\n    param_grid=param_grid,\n    scoring='accuracy',\n    cv=3,\n    verbose=2,\n    n_jobs=-1\n)\n\n# Fit Grid Search\ngrid_search.fit(X_train_smote, y_train_smote)\n\n# Best Parameters\nprint(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n\n# Evaluate on Test Set using best model\nbest_lgb_model = grid_search.best_estimator_\ny_test_pred_best_lgb = best_lgb_model.predict(X_test_strat)\naccuracy_best_lgb = accuracy_score(y_test_strat, y_test_pred_best_lgb)\nprint(\"Optimized LGBM Model accuracy on test set:\", accuracy_best_lgb)\n\n# Classification report for optimized model\nprint(\"\\nOptimized LGBM Classification Report:\\n\", classification_report(y_test_strat, y_test_pred_best_lgb))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Code for Neural Network Model (MLPClassifier)","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize the MLPClassifier with specific hyperparameters\nmlp_model = MLPClassifier(\n    hidden_layer_sizes=(128, 64),  # Two hidden layers with 128 and 64 neurons\n    activation='relu',             # ReLU activation function\n    solver='adam',                 # Optimizer\n    max_iter=500,                  # Max iterations to train the model\n    random_state=42                # For reproducibility\n)\n\n# Train the model with the SMOTE resampled data\nmlp_model.fit(X_train_smote, y_train_smote)\n\n# Make predictions on the test set\ny_test_pred = mlp_model.predict(X_test_strat)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test_strat, y_test_pred)\nprint(\"Model accuracy on test set:\", accuracy)\n\n# Generate a detailed classification report\nprint(\"\\nClassification Report:\\n\", classification_report(y_test_strat, y_test_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}